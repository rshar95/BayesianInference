# -*- coding: utf-8 -*-
"""Bayesian Interference.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kG-06o_B_9bFLBGlWUjpLpyOAbVqsBP7
"""

import pymc3 as pm
import arviz as az
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

def dif_distributions(x,y):
  with pm.Model() as model:
    # define priors
    a = pm.Normal('slope', 0, 16)
    b = pm.Normal('intercept', 0, 16)
    s = pm.Exponential('error', 1)
    
    # predictions
    obs = pm.Normal('observation', a*x + b, s, observed=y)
    
    # use MCMC to sample
    trace = pm.sample(return_inferencedata=True,progressbar=False, tune=1000)
    
  az.plot_posterior(trace)

def bayesian_interference(x,posterior):
  y_pred = posterior['observation']
  y_mean = y_pred.mean(axis=0)
  y_std = y_pred.std(axis=0)
  plt.figure(figsize=(16, 8))
  plt.scatter(x, y, c='k', zorder=10, label='Data')
  plt.plot(x_new, y_mean, label='Prediction Mean')
  plt.fill_between(x_new, y_mean - 3*y_std, y_mean + 3*y_std, alpha=0.33, label='Uncertainty Interval ($\mu\pm3\sigma$)')
  plt.xlabel('$x$')
  plt.ylabel('$y$')
  plt.ylim(-14, 16)
  plt.legend(loc='upper left')

  with pm.Model() as simpler_model:
    pm.glm.GLM.from_formula('y ~ x', dict(x=x, y=y))
    trace = pm.sample()
    
  plt.figure(figsize=(7, 7))
  pm.traceplot(trace)
  plt.tight_layout();

# inputs

x = [
   -1.64934805,  0.52925273,  1.10100092,  0.38566793, -1.56768245,
    1.26195686,  0.92613986, -0.23942803,  0.33933045,  1.14390657,
    0.65466195, -1.36229805, -0.32393554, -0.23258941,  0.17688024,
    1.60774334, -0.22801156,  1.53008133, -1.31431042, -0.27699609
]

# outputs 
y = [
   -3.67385666,  3.37543275,  6.25390538,  1.41569973, -2.08413872,
    6.71560158,  6.32344159,  2.40651236,  4.54217349,  6.25778739,
    4.98933806, -2.69713137,  1.45705571, -0.49772953,  1.50502898,
    7.27228263,  1.6267433 ,  6.43580518, -0.50291509,  0.65674682
]

dif_distributions(x,y)

with pm.Model() as predictive_model:
    a = pm.Normal('slope', 0, 16)
    b = pm.Normal('intercept', 0, 16)
    s = pm.HalfCauchy('error', 1)
    
    x_ = pm.Data('features', x) # a data container, can be changed
    
    obs = pm.Normal('observation', a*x_ + b, s, observed=y)
    
    trace = pm.sample()
    
x_new = np.linspace(-3, 3, 50) # 50 input values between -3 and 3
with predictive_model:
    pm.set_data({'features': x_new})
    posterior = pm.sample_posterior_predictive(trace)

"""1. This plot shows the normal distribution for the slopes,intercent and errors for the input data and target y(s).
2. The following plot shows bayesian interference
"""

bayesian_interference(x,posterior)